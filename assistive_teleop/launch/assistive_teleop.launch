<launch>
  <include file="$(find pr2_machine)/$(env ROBOT).machine" />
  <arg name="kinect_points" default="/head_mount_kinect/depth_registered/points" />
  <arg name="kinect_camera" default="/head_mount_kinect/rgb/image_color" />
  <arg name="run_ft_sensor" default="false" />

  <!-- Rosbridge, Rosapi, Webserver (roswww), and mjpeg_server -->
  <node name="rosbridge" pkg="rosbridge_server" type="rosbridge.py" output="screen">
      <param name="port" type="int" value="9091" />
  </node>
  
  <node name="rosapi" pkg="rosapi" type="rosapi.py" output="screen"/>

  <rosparam> 'http/default': 8000 </rosparam>
  <node name="roswww" pkg="roswww" type="webserver.py" output="screen"/>

  <node pkg="mjpeg_server" type="mjpeg_server"  name="mjpeg_server" output="screen">
      <param name="port" type="int" value="8080" />
  </node>

  <!-- Throttling nodes for robot state -->
  <node name="torso_state_throttle" pkg="topic_tools" type="throttle"
        args="messages /torso_controller/state 2 /torso_controller/state_throttled" />

  <node name="head_state_throttle" pkg="topic_tools" type="throttle"
        args="messages /head_traj_controller/state 4 /head_traj_controller/state_throttled" />

  <node name="r_gripper_state_throttle" pkg="topic_tools" type="throttle"
        args="messages /r_gripper_controller/state 1 /r_gripper_controller/state_throttled" />

  <node name="l_gripper_state_throttle" pkg="topic_tools" type="throttle" 
        args="messages /l_gripper_controller/state 1 /l_gripper_controller/state_throttled" />

  <node if="$(arg run_ft_sensor)" name="throttle_wt_force_out" pkg="topic_tools" type="throttle"
        args="messages /netft_gravity_zeroing/wrench_zeroed 10 /wt_force_out_throttle" />

  <!-- Image Rotation Nodes for right + left arm cameras and ar_confirm image -->
  <node name="image_rotater_right" pkg="image_rotate" type="image_rotate" machine = "c1"> 
    <remap from="image" to="/r_forearm_cam/image_color"/>
    <remap from="rotated/image" to="/r_forearm_cam/image_color_rotated"/>
  </node>

  <node name="image_rotater_left" pkg="image_rotate" type="image_rotate" machine="c1"> 
    <remap from="image" to="/l_forearm_cam/image_color"/>
    <remap from="rotated/image" to="/l_forearm_cam/image_color_rotated"/>
  </node>

  <!-- Text-to-speech backend -->
  <node pkg ="assistive_teleop" type="speech_intermediary.py" name="wt_speech_intermediary">
    <param name="voice" value="voice_nitech_us_rms_arctic_hts"/>
  </node>

  <!-- Pixel_2_3d: Returns PoseStamped with point and normal from click on image with kinect -->
  <node name="pixel_2_3d" pkg="pixel_2_3d" type="pixel_2_3d" machine="c1" output="screen" >
      <remap from="image" to="$(arg kinect_camera)" />
      <remap from="point_cloud" to="$(arg kinect_points)" />
      <param name="normal_radius" type="double" value="0.035" />
      <param name="use_closest_pixel"  value="True"/>
  </node>

  <node name="clicked_pose_relay" pkg="assistive_teleop" type="clicked_pose_relay.py" 
        args="-r -1.570796 3.14159 0." output="screen" >
      <remap from="pose_in" to="/wt_clicked_pose" />
      <remap from="pose_out" to="/haptic_mpc/goal_pose" />
  </node>

  <!--Setup Cartesian Controller for arm movements -->
  <arg name="l_cart_step_pose_goal" default="l_cart/command" />
  <arg name="r_cart_step_pose_goal" default="r_cart/command" />
  <include file="$(find assistive_teleop)/launch/jttask_cart_controller.launch" >
    <arg name="use_left_arm" default="true" />
    <arg name="use_right_arm" default="true" />
  </include>

  <node pkg="assistive_teleop" name="l_twist_to_pose" type="twist_to_pose.py" output="screen">
    <remap from="twist_in" to="l_cart/web_commands" />
    <remap from="pose_out" to="$(arg l_cart_step_pose_goal)" />
  </node>

  <node pkg="assistive_teleop" name="r_twist_to_pose" type="twist_to_pose.py" output="screen">
    <remap from="twist_in" to="r_cart/web_commands" />
    <remap from="pose_out" to="$(arg r_cart_step_pose_goal)"/>
  </node>

</launch>
